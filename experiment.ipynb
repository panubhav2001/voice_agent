{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e60f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav Prasad\\anaconda3\\envs\\py3115\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "import io\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "659d28ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Deepgram API config\n",
    "DG_API_KEY = os.getenv(\"DEEPGRAM_API_KEY\")\n",
    "MODEL_NAME = \"model=aura-2-callista-en\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "040818e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_audio_ffplay(wav_io: io.BytesIO):\n",
    "    \"\"\"Plays in-memory WAV audio using ffplay (must be installed).\"\"\"\n",
    "    process = subprocess.Popen(\n",
    "        [\"ffplay\", \"-autoexit\", \"-\", \"-nodisp\"],\n",
    "        stdin=subprocess.PIPE,\n",
    "        stdout=subprocess.DEVNULL,\n",
    "        stderr=subprocess.DEVNULL\n",
    "    )\n",
    "    process.stdin.write(wav_io.read())\n",
    "    process.stdin.close()\n",
    "    process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95fa56de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'054ed5b3845b5790677deb151dd4192b1fe183df'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEEPGRAM_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36fdcb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "speaker is None. Return immediately\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during TTS synthesis or playback: DeepgramError: Speaker is not initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in AbstractSyncWebSocketClient._listening: synthesize_response.<locals>.on_audio() got an unexpected keyword argument 'data'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "from deepgram import DeepgramClient, SpeakWSOptions, SpeakWebSocketEvents\n",
    "\n",
    "# Load .env with API key\n",
    "load_dotenv()\n",
    "DEEPGRAM_API_KEY = os.getenv(\"DEEPGRAM_API_KEY\")\n",
    "\n",
    "def is_installed(command: str) -> bool:\n",
    "    return shutil.which(command) is not None\n",
    "\n",
    "def synthesize_response(text: str):\n",
    "    if not is_installed(\"ffplay\"):\n",
    "        raise RuntimeError(\"ffplay (from ffmpeg) is required. Please install it and add to PATH.\")\n",
    "\n",
    "    try:\n",
    "        # Initialize Deepgram client\n",
    "        deepgram = DeepgramClient(DEEPGRAM_API_KEY)\n",
    "\n",
    "        # Create WebSocket connection\n",
    "        connection = deepgram.speak.websocket.v(\"1\")\n",
    "\n",
    "        # Start ffplay to play raw audio\n",
    "        player = subprocess.Popen(\n",
    "            [\"ffplay\", \"-autoexit\", \"-nodisp\", \"-\"],\n",
    "            stdin=subprocess.PIPE,\n",
    "            stdout=subprocess.DEVNULL,\n",
    "            stderr=subprocess.DEVNULL,\n",
    "        )\n",
    "\n",
    "        # Handle audio event (MUST take 1 positional arg: event object)\n",
    "        def on_audio(event):\n",
    "            if player.stdin and hasattr(event, \"data\") and event.data:\n",
    "                player.stdin.write(event.data)\n",
    "                player.stdin.flush()\n",
    "\n",
    "        # Register the handler\n",
    "        connection.on(SpeakWebSocketEvents.AudioData, on_audio)\n",
    "\n",
    "        # Configure options\n",
    "        options = SpeakWSOptions(\n",
    "            model=\"aura-2-thalia-en\",\n",
    "            encoding=\"linear16\",\n",
    "            sample_rate=16000\n",
    "        )\n",
    "\n",
    "        # Start WebSocket connection\n",
    "        connection.start(options)\n",
    "        connection.send_text(text)\n",
    "        connection.flush()\n",
    "        connection.wait_for_complete()\n",
    "        connection.finish()\n",
    "\n",
    "        # Close ffplay\n",
    "        if player.stdin:\n",
    "            player.stdin.close()\n",
    "        player.wait()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during TTS synthesis or playback: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    synthesize_response(\"This is a working Deepgram TTS integration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "314496ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Š Connection opened.\n",
      "âœ… Connection closed.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from deepgram import (\n",
    "    DeepgramClient,\n",
    "    DeepgramClientOptions,\n",
    "    SpeakWebSocketEvents,\n",
    "    SpeakWSOptions\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import signal\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "DEEPGRAM_API_KEY = os.getenv(\"DEEPGRAM_API_KEY\")\n",
    "\n",
    "# Setup Deepgram client with speaker playback enabled\n",
    "config = DeepgramClientOptions(\n",
    "    options={\n",
    "        \"speaker_playback\": \"true\"  # Enables real-time audio playback via system speaker\n",
    "    }\n",
    ")\n",
    "\n",
    "deepgram = DeepgramClient(DEEPGRAM_API_KEY, config)\n",
    "\n",
    "async def synthesize_response(text: str):\n",
    "    try:\n",
    "        # Create async WebSocket connection\n",
    "        dg_connection = deepgram.speak.asyncwebsocket.v(\"1\")\n",
    "\n",
    "        # Event Handlers (Optional Debug Output)\n",
    "        async def on_open(self, open, **kwargs):\n",
    "            print(\"ðŸ”Š Connection opened.\")\n",
    "\n",
    "        async def on_error(self, error, **kwargs):\n",
    "            print(f\"âŒ Error: {error}\")\n",
    "\n",
    "        async def on_close(self, close, **kwargs):\n",
    "            print(\"âœ… Connection closed.\")\n",
    "\n",
    "        # Register events\n",
    "        dg_connection.on(SpeakWebSocketEvents.Open, on_open)\n",
    "        dg_connection.on(SpeakWebSocketEvents.Error, on_error)\n",
    "        dg_connection.on(SpeakWebSocketEvents.Close, on_close)\n",
    "\n",
    "        # Setup WebSocket TTS options\n",
    "        options = SpeakWSOptions(\n",
    "            model=\"aura-2-thalia-en\",\n",
    "            encoding=\"linear16\",\n",
    "            sample_rate=16000\n",
    "        )\n",
    "\n",
    "        # Start the TTS WebSocket connection\n",
    "        started = await dg_connection.start(options)\n",
    "        if not started:\n",
    "            print(\"âŒ Failed to start the TTS connection.\")\n",
    "            return\n",
    "\n",
    "        # Send text and flush to initiate playback\n",
    "        await dg_connection.send_text(text)\n",
    "        await dg_connection.flush()\n",
    "        await dg_connection.wait_for_complete()\n",
    "        await dg_connection.finish()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during TTS synthesis or playback: {e}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    await synthesize_response(\"Hello! I am your voice assistant using Deepgram TTS.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eaccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from deepgram import (\n",
    "    DeepgramClient,\n",
    "    DeepgramClientOptions,\n",
    "    LiveTranscriptionEvents,\n",
    "    LiveOptions,\n",
    "    Microphone,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class TranscriptCollector:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.transcript_parts = []\n",
    "\n",
    "    def add_part(self, part):\n",
    "        self.transcript_parts.append(part)\n",
    "\n",
    "    def get_full_transcript(self):\n",
    "        return ' '.join(self.transcript_parts)\n",
    "\n",
    "\n",
    "transcript_collector = TranscriptCollector()\n",
    "\n",
    "async def start_live_transcription():\n",
    "    try:\n",
    "        config = DeepgramClientOptions(options={\"keepalive\": \"true\"})\n",
    "        deepgram = DeepgramClient(os.getenv(\"DEEPGRAM_API_KEY\"), config)\n",
    "\n",
    "        dg_connection = deepgram.listen.asynclive.v(\"1\")\n",
    "\n",
    "        queue = asyncio.Queue()\n",
    "\n",
    "        async def on_message(self, result, **kwargs):\n",
    "            sentence = result.channel.alternatives[0].transcript\n",
    "            if not result.speech_final:\n",
    "                transcript_collector.add_part(sentence)\n",
    "            else:\n",
    "                transcript_collector.add_part(sentence)\n",
    "                full_sentence = transcript_collector.get_full_transcript()\n",
    "                await queue.put(full_sentence)\n",
    "                transcript_collector.reset()\n",
    "\n",
    "        async def on_error(self, error, **kwargs):\n",
    "            print(f\"\\n\\n{error}\\n\\n\")\n",
    "\n",
    "        dg_connection.on(LiveTranscriptionEvents.Transcript, on_message)\n",
    "        dg_connection.on(LiveTranscriptionEvents.Error, on_error)\n",
    "\n",
    "        options = LiveOptions(\n",
    "            model=\"nova-2\",\n",
    "            punctuate=True,\n",
    "            language=\"en-US\",\n",
    "            encoding=\"linear16\",\n",
    "            channels=1,\n",
    "            sample_rate=16000,\n",
    "            endpointing=True\n",
    "        )\n",
    "\n",
    "        await dg_connection.start(options)\n",
    "\n",
    "        microphone = Microphone(dg_connection.send)\n",
    "        microphone.start()\n",
    "\n",
    "        # Silence detection setup\n",
    "        silence_timeout = 2  # seconds\n",
    "        last_spoken_time = asyncio.get_event_loop().time()\n",
    "\n",
    "        while True:\n",
    "            if not microphone.is_active():\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                result = queue.get_nowait()\n",
    "                yield result\n",
    "                last_spoken_time = asyncio.get_event_loop().time()\n",
    "            except asyncio.QueueEmpty:\n",
    "                await asyncio.sleep(0.1)\n",
    "\n",
    "            if asyncio.get_event_loop().time() - last_spoken_time > silence_timeout:\n",
    "                break\n",
    "\n",
    "        microphone.finish()\n",
    "        await dg_connection.finish()\n",
    "        print(\"Finished\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not open socket: {e}\")\n",
    "    finally:\n",
    "        # Ensure all tasks are properly closed\n",
    "        if 'microphone' in locals():\n",
    "            microphone.finish()\n",
    "        if 'dg_connection' in locals():\n",
    "            await dg_connection.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c9411e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Prasad\\AppData\\Local\\Temp\\ipykernel_12484\\2031674868.py:36: UnsupportedWarning: asynclive is unsupported as of 4.0.0. deepgram.listen.asynclive is deprecated. Use deepgram.listen.asyncwebsocket instead.\n",
      "  dg_connection = deepgram.listen.asynclive.v(\"1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Transcribed] Hello. Hello. Hello.\n",
      "[Transcribed] Hello.\n",
      "[Transcribed] Hello.\n",
      "[Transcribed] Hello.\n",
      "[Transcribed] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tasks cancelled error: \n",
      "tasks cancelled error: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "async for transcript in start_live_transcription():\n",
    "    print(f\"[Transcribed] {transcript}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91aaea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3115",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
